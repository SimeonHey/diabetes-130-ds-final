{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    full = os.path.join('diabetes', path)\n",
    "    return pd.read_csv(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_csv('IDs_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = load_csv('diabetic_data_balanced.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(original['metformin-pioglitazone'] != 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values & redundant columns\n",
    "* Drop `weight`\n",
    "* Drop `payer_code`\n",
    "* Create an `unknown` group for `medical_speciality`\n",
    "* Get rid of singular columns\n",
    "* Get rid of columns that have nothing to do with prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original.copy()\n",
    "\n",
    "def get_na_info(df):\n",
    "    nas = df.isna().sum()\n",
    "    nas = nas[nas > 0]\n",
    "    return nas\n",
    "\n",
    "print(\"NA info in the begginning:\")\n",
    "print(get_na_info(df))\n",
    "\n",
    "df.drop('weight', axis=1, inplace=True)\n",
    "df.drop('payer_code', axis=1, inplace=True)\n",
    "df.drop('diag_1', axis=1, inplace=True)\n",
    "df.drop('diag_2', axis=1, inplace=True)\n",
    "df.drop('diag_3', axis=1, inplace=True)\n",
    "\n",
    "df['medical_specialty'].fillna(value=unknown_token, inplace=True)\n",
    "df['race'].fillna(value=unknown_token, inplace=True)\n",
    "\n",
    "print(\"NA info after cleanup\")\n",
    "print(get_na_info(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_pairs(df):\n",
    "    pairs = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        pairs.append((col, df[col].unique().shape[0]))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def get_singular_cols(df):\n",
    "    singular_cols = []\n",
    "    unq_pairs = get_unique_pairs(df)\n",
    "    \n",
    "    for col, unq in unq_pairs:\n",
    "        if unq == 1:\n",
    "            singular_cols.append(col)\n",
    "    return singular_cols\n",
    "\n",
    "sing = get_singular_cols(df)\n",
    "print(\"Singular columns before\", sing)\n",
    "df.drop(sing, axis=1, inplace=True)\n",
    "print(\"Singular columns after\", get_singular_cols(df))\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique pairs before:')\n",
    "print(get_unique_pairs(df))\n",
    "\n",
    "df.drop('encounter_id', axis=1, inplace=True)\n",
    "#TODO: Could drop subsequent patient visits\n",
    "df.drop('patient_nbr', axis=1, inplace=True)\n",
    "\n",
    "print('Unique pairs after:')\n",
    "print(get_unique_pairs(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical values\n",
    "\n",
    "* Encode `age` as the medium between the two boundaries\n",
    "* Encode `[admission_type_id, discharge_disposition_id, admission_source_id]` and all non-numerical columns to binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ages = np.linspace(5, 95, 10)\n",
    "cat_ages = df['age'].unique()\n",
    "\n",
    "for cat, num in zip(cat_ages, num_ages):\n",
    "    print(cat,'with', num)\n",
    "    df['age'].replace(to_replace=cat, value=num, inplace=True)\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df[\"readmitted\"]\n",
    "df.drop(\"readmitted\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "to_bin = np.concatenate([id_cols, categorical_cols])\n",
    "print(to_bin)\n",
    "to_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def bin_column(df, cols):\n",
    "    return pd.get_dummies(df, columns=cols, drop_first=True)\n",
    "\n",
    "bin_column(df, to_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/test & Scale\n",
    "* `from sklearn.model_selection import StratifiedShuffleSplit`\n",
    "* `from sklearn.preprocessing import StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "* 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "* RMSE & accuracy\n",
    "* Confusion matrix\n",
    "* F1 (or Fx) scores & compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
